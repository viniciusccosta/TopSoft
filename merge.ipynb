{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação:\n",
    "\n",
    "import pandas as pd\n",
    "from topsoft.database import configure_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o banco de dados e as tabelas necessárias (se ainda não existirem)\n",
    "\n",
    "configure_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "DADOS DOS ALUNOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo arquivo de alunos (exportado pelo TopSoft) com os dados já recebidos da API da ActivitySoft:\n",
    "\n",
    "# TODO: Force each column to be a specific type\n",
    "df_activity = pd.read_json(\n",
    "    \"alunos.json\",\n",
    "    dtype={\n",
    "        \"cartao_acesso\": \"string\",\n",
    "        \"celular\": \"string\",\n",
    "        \"cpf\": \"string\",\n",
    "        \"data_nascimento\": \"date\",\n",
    "        \"email\": \"string\",\n",
    "        \"filiacao_1_id\": \"int\",\n",
    "        \"filiacao_2_id\": \"int\",\n",
    "        \"foto_data_hora_alteracao\": \"date\",\n",
    "        \"id\": \"int\",\n",
    "        \"id_turmas\": \"string\",\n",
    "        \"matricula\": \"string\",\n",
    "        \"nome\": \"string\",\n",
    "        \"responsaveis_adicionais_ids\": \"string\",\n",
    "        \"responsavel_id\": \"int\",\n",
    "        \"responsavel_secundario_id\": \"int\",\n",
    "        \"sexo\": \"string\",\n",
    "        \"tipo_liberacao\": \"string\",\n",
    "        \"unidade_id\": \"int\",\n",
    "        \"url_foto\": \"string\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Drop column id to not conflict with the database primary key:\n",
    "df_activity.drop(columns=[\"id\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Formatando os nomes para garantir que não excedam 40 caracteres e removendo espaços extras:\n",
    "df_activity[\"nome\"] = df_activity[\"nome\"].apply(lambda x: x[0:40].strip())\n",
    "\n",
    "\n",
    "# Strip all string columns to remove leading/trailing spaces:\n",
    "def strip_string_columns(df):\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        df[col] = df[col].str.strip()\n",
    "    return df\n",
    "\n",
    "\n",
    "df_activity = strip_string_columns(df_activity)\n",
    "\n",
    "# Forçando as colunas de data para o formato correto:\n",
    "df_activity[\"data_nascimento\"] = pd.to_datetime(\n",
    "    df_activity[\"data_nascimento\"], errors=\"coerce\"\n",
    ").dt.date\n",
    "df_activity[\"foto_data_hora_alteracao\"] = pd.to_datetime(\n",
    "    df_activity[\"foto_data_hora_alteracao\"], errors=\"coerce\"\n",
    ").dt.date\n",
    "\n",
    "# Ordenando o DataFrame por nome:\n",
    "df_activity.sort_values(by=\"nome\", inplace=True)\n",
    "display(df_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMA POSSÍVEL SOLUÇÃO PARA LER OS DADOS DO ALUNO DIRETAMENTE DO BANCO DE DADOS\n",
    "\n",
    "# import sqlite3\n",
    "\n",
    "# conn = sqlite3.connect('meu_banco.db')\n",
    "# df_activity = pd.read_sql_table('minha_tabela', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validando se não existem nomes duplicados:\n",
    "\n",
    "if df_activity[\"nome\"].duplicated().any():\n",
    "    print(\"Existem nomes duplicados no DataFrame de alunos.\")\n",
    "    display(df_activity[df_activity[\"nome\"].duplicated(keep=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "ARQUIVO BILHETES.TXT CONTENDO NUMERO DA CARTEIRINHA + NOME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo arquivo de carteirinhas (algum já pre-existente ou exportado pelo TopSoft):\n",
    "\n",
    "with open(r\"gi5_cartoes.txt\", \"r\") as file:\n",
    "    dados = file.read()\n",
    "\n",
    "linhas = dados.split(\"\\n\")\n",
    "carteirinhas = [{\"cartao\": i[0:16], \"nome\": i[16 : 16 + 40]} for i in linhas]\n",
    "\n",
    "# Criando DataFrame de carteirinhas:\n",
    "df_cartoes = pd.DataFrame(carteirinhas)\n",
    "\n",
    "# Formatando os nomes para garantir que não excedam 40 caracteres e removendo espaços extras:\n",
    "df_cartoes[\"nome\"] = df_cartoes[\"nome\"].apply(lambda x: x[0:40].strip())\n",
    "\n",
    "# Drop empty names\n",
    "df_cartoes = df_cartoes[df_cartoes[\"nome\"] != \"\"]\n",
    "\n",
    "# Ordenando o DataFrame por nome:\n",
    "df_cartoes.sort_values(by=\"nome\", inplace=True)\n",
    "display(df_cartoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validando se não existem nomes duplicados:\n",
    "\n",
    "\n",
    "if df_cartoes[\"nome\"].duplicated().any():\n",
    "\n",
    "\n",
    "    print(\"Existem nomes duplicados no DataFrame de carteirinhas.\")\n",
    "\n",
    "    display(df_cartoes[df_cartoes[\"nome\"].duplicated(keep=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "PRIMEIRO MERGE: TENTANDO VINCULAR CADA CARTEIRINHA A UM ALUNO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dos DataFrames para vincular cada carteirinha ao aluno correspondente (baseado no nome):\n",
    "\n",
    "df_merged = pd.merge(df_activity, df_cartoes, left_on=\"nome\", right_on=\"nome\")\n",
    "display(df_merged[[\"nome\", \"cartao\", \"matricula\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos atualizar o Banco de Dados local com os dados do DataFrame:\n",
    "\n",
    "from topsoft.repository import (\n",
    "    bind_cartao_acesso_to_aluno,\n",
    "    get_or_create_cartao_acesso,\n",
    "    get_or_create_aluno,\n",
    ")\n",
    "\n",
    "for index, row in df_merged.iterrows():\n",
    "    cartao_acesso = get_or_create_cartao_acesso(row[\"cartao\"])\n",
    "\n",
    "    # Convert row to dict and remove NaN values\n",
    "    dict_row = row.to_dict()\n",
    "    dict_row = {k: v for k, v in dict_row.items() if pd.notna(v)}\n",
    "    dict_row = {k: v for k, v in dict_row.items() if v is not None}\n",
    "    # TODO: We could drop NaN values directly in the DataFrame before iterating, but this is a quick fix.\n",
    "\n",
    "    # Create or get the aluno, passing all row values as keyword arguments\n",
    "    aluno = get_or_create_aluno(**dict_row)\n",
    "\n",
    "    bind_cartao_acesso_to_aluno(\n",
    "        cartao_acesso_id=cartao_acesso.id,\n",
    "        aluno_id=aluno.id,\n",
    "    )\n",
    "    print(f\"Cartão {cartao_acesso.numeracao} vinculado ao aluno {aluno.nome}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "SEGUNDO MERGE: CRIAR SUPOSTOS ALUNOS (POSSIVELMENTE FUNCIONÁRIOS) QUE ESTÃO PRESENTES NOS DADOS DA CATRACAS, MAS POR ALGUM MOTIVO NÃO ESTÃO NA LISTA COM OS DADOS DOS ALUNOS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Também será necessário criar \"alunos\" para as carteirinhas que não possuem aluno correspondente (ainda), possivelmente é um funcionário...\n",
    "\n",
    "not_aluno_df = df_cartoes[~df_cartoes[\"nome\"].isin(df_activity[\"nome\"])]\n",
    "not_aluno_df = not_aluno_df.copy()\n",
    "not_aluno_df[\"matricula\"] = not_aluno_df[\"cartao\"].apply(lambda x: f\"cartao_{x}\")\n",
    "display(not_aluno_df[[\"nome\", \"cartao\", \"matricula\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos atualizar o Banco de Dados local com os dados do DataFrame:\n",
    "\n",
    "from topsoft.repository import (\n",
    "    bind_cartao_acesso_to_aluno,\n",
    "    get_or_create_cartao_acesso,\n",
    "    get_or_create_aluno,\n",
    ")\n",
    "\n",
    "for index, row in not_aluno_df.iterrows():\n",
    "    cartao_acesso = get_or_create_cartao_acesso(row[\"cartao\"])\n",
    "\n",
    "    # Convert row to dict and remove NaN values\n",
    "    dict_row = row.to_dict()\n",
    "    dict_row = {k: v for k, v in dict_row.items() if pd.notna(v)}\n",
    "    dict_row = {k: v for k, v in dict_row.items() if v is not None}\n",
    "    # TODO: We could drop NaN values directly in the DataFrame before iterating, but this is a quick fix.\n",
    "\n",
    "    # Create or get the aluno, passing all row values as keyword arguments\n",
    "    aluno = get_or_create_aluno(**dict_row)\n",
    "\n",
    "    # Bulk update\n",
    "    bind_cartao_acesso_to_aluno(\n",
    "        cartao_acesso_id=cartao_acesso.id,\n",
    "        aluno_id=aluno.id,\n",
    "    )\n",
    "    print(f\"Cartão {cartao_acesso.numeracao} vinculado ao aluno {aluno.nome}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topsoft-z2RmIakO-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
